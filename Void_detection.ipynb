{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57565368-1e50-479b-b473-7132303f2ed7",
   "metadata": {},
   "source": [
    "# Region Detection Comparing different Segmentation Methods and Hough Circle Detection\n",
    "\n",
    "This program defines the functions for threshold, K-Means, DBSCAN, and watershed methods for detecting ice void regions in the PMCs. The Hough Transform is passed on the boundaries of each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60527d8-52fb-4cc6-bb8b-f454874953a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect regions using DBSCAN clustering\n",
    "def detect_regions_dbscan(cloud_albedo, eps=0.35, min_samples=15):\n",
    "    albedo_flat = cloud_albedo.flatten()  # Flatten the 2D albedo array to 1D\n",
    "    coordinates = np.array([(i, j) for i in range(cloud_albedo.shape[0]) for j in range(cloud_albedo.shape[1])])  # Create a list of (row, column) coordinate pairs\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(coordinates, sample_weight=albedo_flat)  # Apply DBSCAN clustering with given parameters\n",
    "    labels = clustering.labels_.reshape(cloud_albedo.shape)  # Reshape the 1D label array back to 2D\n",
    "    regions_map = (labels == -1).astype(int)  # Convert void regions (label -1) to 1, others to 0\n",
    "    return regions_map  # Return the binary regions map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3c8b3-96ad-4aa6-8064-5693e66c960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect regions using a threshold method\n",
    "def detect_regions_threshold(cloud_albedo, threshold=2, min_region_size=100, max_region_size=50000):\n",
    "    binary_albedo = np.where(cloud_albedo > threshold, 0, 1)  # Binarize albedo data based on threshold\n",
    "    dilated_albedo = ndimage.binary_dilation(binary_albedo, structure=np.ones((3, 3)))  # Dilate the binary image to fill small gaps\n",
    "    border = dilated_albedo - binary_albedo  # Identify the border regions\n",
    "    surrounded_regions = dilated_albedo - border  # Extract the regions fully surrounded by others\n",
    "    labeled_regions, num_regions = ndimage.label(surrounded_regions)  # Label the connected regions\n",
    "    region_sizes = ndimage.sum(surrounded_regions, labeled_regions, range(1, num_regions + 1))  # Calculate the size of each region\n",
    "    region_mask = np.isin(labeled_regions, np.where((region_sizes > min_region_size) & (region_sizes < max_region_size))[0] + 1)  # Create a mask for regions within the size limits\n",
    "    return region_mask  # Return the mask of valid regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8ce53-8abd-4be8-8521-ededaebcdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect regions using the watershed algorithm\n",
    "def detect_watershed_albedo_(cloud_albedo, min_region_size=100, max_region_size=250000):\n",
    "    gradient = sobel(cloud_albedo)  # Calculate the gradient magnitude of the albedo image\n",
    "    local_min = local_minima(cloud_albedo)  # Detect local minima in the albedo image\n",
    "    markers = label(local_min)  # Label the local minima markers\n",
    "    labels = watershed(cloud_albedo, markers=markers)  # Apply the watershed algorithm using the gradient and markers\n",
    "    valid_labels = [region.label for region in regionprops(labels) if min_region_size <= region.area <= max_region_size]  # Filter regions based on size\n",
    "    region_mask = np.isin(labels, valid_labels)  # Create a mask for valid regions\n",
    "    return labels  # Return the labeled regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61850f94-10af-4799-b1b3-f21af47e8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect regions using KMeans clustering\n",
    "def detect_regions_kmeans(cloud_albedo, n_clusters=4):\n",
    "    albedo_flat = cloud_albedo.flatten()  # Flatten the 2D albedo array to 1D\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(albedo_flat.reshape(-1, 1))  # Apply KMeans clustering with given number of clusters\n",
    "    cluster_labels = kmeans.labels_ + 1  # Adjust labels to avoid 0 as background\n",
    "    cluster_labels_2d = cluster_labels.reshape(cloud_albedo.shape)  # Reshape the 1D label array back to 2D\n",
    "    return cluster_labels_2d  # Return the 2D array of cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a32383-be5f-4677-b995-ed79028f9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot albedo data with detected regions and contours\n",
    "def plot_albedo_with_regions_contours(cloud_albedo, regions_map, title='', min_size=100, max_size=250000, method_name=''):\n",
    "    plt.figure(figsize=(16, 10))  # Set the figure size\n",
    "    plt.rcParams.update({'font.size': 20})  # Update the font size\n",
    "    \n",
    "    # Plot the original albedo data\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(cloud_albedo, cmap='Blues_r')  # Display albedo data with 'Blues_r' colormap\n",
    "    plt.colorbar(label='Cloud Albedo')  # Add colorbar with label\n",
    "    plt.title('Cloud Albedo')  # Add title\n",
    "    plt.xlabel('X Pixel')  # Add X-axis label\n",
    "    plt.ylabel('Y Pixel')  # Add Y-axis label\n",
    "    \n",
    "    # Plot the albedo data with detected regions\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(cloud_albedo, cmap='Blues_r')  # Display albedo data again\n",
    "    plt.colorbar(label='Cloud Albedo')  # Add colorbar with label\n",
    "    plt.title('Detected Regions')  # Add title\n",
    "    plt.xlabel('X Pixel')  # Add X-axis label\n",
    "    plt.ylabel('Y Pixel')  # Add Y-axis label\n",
    "    \n",
    "    labeled_regions = label(regions_map)  # Label the detected regions\n",
    "    props = regionprops(labeled_regions)  # Get properties of labeled regions\n",
    "    \n",
    "    # List of colors for contours\n",
    "    colors = [\n",
    "        '#FF00FF', '#00FFFF', '#FFFF00', '#00FF00', '#FF0000', '#0000FF',\n",
    "        '#FF6600', '#CCFF00', '#FF33CC', '#33FF33', '#6633FF', '#FF3399'\n",
    "    ]\n",
    "    \n",
    "    # Plot the contours of each region\n",
    "    for i, prop in enumerate(props):\n",
    "        if prop.area >= min_size:  # Only plot regions larger than min_size\n",
    "            color = colors[i % len(colors)]  # Cycle through the list of colors\n",
    "            contours = find_contours(labeled_regions == prop.label, 0.5)  # Find contours for the region\n",
    "            for contour in contours:\n",
    "                plt.plot(contour[:, 1], contour[:, 0], color=color)  # Plot the contour with the specified color\n",
    "    \n",
    "    # Plot the albedo data with Hough Transform circles\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(cloud_albedo, cmap='gray')  # Display albedo data with 'gray' colormap\n",
    "    plt.colorbar(label='Cloud Albedo')  # Add colorbar with label\n",
    "    plt.title('Detected Regions with Hough Transform Circles')  # Add title\n",
    "    plt.xlabel('X Pixel')  # Add X-axis label\n",
    "    plt.ylabel('Y Pixel')  # Add Y-axis label\n",
    "    \n",
    "    edges = np.zeros_like(labeled_regions, dtype=np.uint8)  # Create an empty array for edges\n",
    "    \n",
    "    # Find contours and edges for regions within size limits\n",
    "    for i, prop in enumerate(props):\n",
    "        if min_size <= prop.area <= max_size:  # Only consider regions within size limits\n",
    "            region_mask = (labeled_regions == prop.label)  # Create a mask for the region\n",
    "            contours = find_contours(region_mask, level=0.5)  # Find contours for the region\n",
    "            for contour in contours:\n",
    "                contour = np.round(contour).astype(int)  # Round contour coordinates to integers\n",
    "                edges[contour[:, 0], contour[:, 1]] = 1  # Mark edges in the array\n",
    "                \n",
    "    # Apply Hough Transform to find circles\n",
    "    if np.any(edges):  # Only if there are edges detected\n",
    "        hough_radii = np.arange(20, 300)  # Define a range of radii to search for circles\n",
    "        hough_res = hough_circle(edges.astype(np.uint8), hough_radii)  # Apply Hough Transform\n",
    "        accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=20, min_ydistance=20, total_num_peaks=5)  # Find peaks in the Hough space\n",
    "        for center_y, center_x, radius in zip(cy, cx, radii):  # Plot each detected circle\n",
    "            circle = Circle((center_x, center_y), radius=radius, fill=False, color='red', linewidth=2)  # Create a red circle\n",
    "            plt.gca().add_patch(circle)  # Add the circle to the plot\n",
    "    \n",
    "    plt.suptitle(title)  # Add the overall title\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aef91b-222b-44bc-a3ae-d27c8b4b7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = '/mnt/home/anaise.gaillard/.conda/envs/watershed/share/proj'  # Set the environment variable for PROJ library path\n",
    "\n",
    "# Function to unzip a gzipped file\n",
    "def gunzip_shutil(source_filepath, dest_filepath, block_size=1024*1024):\n",
    "    with gzip.open(source_filepath, 'rb') as s_file, open(dest_filepath, 'wb') as d_file:  # Open the source file for reading and destination file for writing\n",
    "        shutil.copyfileobj(s_file, d_file, block_size)  # Copy content from source to destination in chunks of block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049db1df-5094-49dc-bd22-c7d15b2def9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of orbit files with paths to compressed and uncompressed files\n",
    "orbits_dic = {\n",
    "    '01292': ('/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01292_2007-202_v05.20_r05_cat.nc.gz', \n",
    "              '/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01292_2007-202_v05.20_r05_cld.nc.gz'),\n",
    "    '01269': ('/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01269_2007-200_v05.20_r05_cat.nc.gz', \n",
    "              '/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01269_2007-200_v05.20_r05_cld.nc.gz'),\n",
    "    '01263': ('/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01263_2007-200_v05.20_r05_cat.nc.gz', \n",
    "              '/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01263_2007-200_v05.20_r05_cld.nc.gz'),\n",
    "    '01240': ('/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01240_2007-199_v05.20_r05_cat.nc.gz', \n",
    "              '/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_01240_2007-199_v05.20_r05_cld.nc.gz'),\n",
    "    '00814': ('/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_00814_2007-170_v05.20_r05_cat.nc.gz', \n",
    "              '/data/aim/interim_archive/cips/data/PMC/north_2007/level_2/ver_05.20/rev_05/cips_sci_2_orbit_00814_2007-170_v05.20_r05_cld.nc.gz')\n",
    "}\n",
    "\n",
    "# Dictionary of methods to detect regions\n",
    "methods = {\n",
    "    \"DBSCAN\": detect_regions_dbscan,\n",
    "    \"KMeans\": detect_regions_kmeans,\n",
    "    \"Threshold\": detect_regions_threshold,\n",
    "    \"Watershed\": detect_watershed_albedo_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb922a5b-4a00-4abc-bab8-4a7bbdbafe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each orbit\n",
    "for orbit, (catfile, cldfile) in orbits_dic.items():\n",
    "    # Unzip files\n",
    "    gunzip_shutil(catfile, 'geolocation.nc')  # Unzip the catalog file\n",
    "    gunzip_shutil(cldfile, 'cloud.nc')  # Unzip the cloud file\n",
    "    \n",
    "    # Load cloud data from the unzipped file\n",
    "    cloud_data = nc.Dataset('cloud.nc')  # Open the NetCDF file\n",
    "    cloud_albedo = cloud_data['CLD_ALBEDO'][:]  # Extract the albedo data\n",
    "    cloud_albedo_nan = np.nan_to_num(cloud_albedo, nan=-1000)  # Replace NaNs with -1000\n",
    "    \n",
    "    # Apply each method to detect regions and plot results\n",
    "    for method_name, method_func in methods.items():  # Iterate over each method\n",
    "        regions_map = method_func(cloud_albedo_nan)  # Detect regions using the current method\n",
    "        plot_albedo_with_regions_contours(cloud_albedo, regions_map, title=f'Orbit {orbit} - Method {method_name}', min_size=100, max_size=250000)  # Plot the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(aim)",
   "language": "python",
   "name": "aim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
